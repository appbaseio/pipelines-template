# Vector Indexing with OpenAI Pipeline

This pipeline demonstrates how an indexing pipeline can be created that supports indexing vectors automatically to be used in kNN while searching by leveraging OpenAI's Embeddings API.

[Deploy this pipeline with just a click](https://dashboard.reactivesearch.io/deploy?template=https://raw.githubusercontent.com/appbaseio/pipelines-template/master/openai_indexing/pipeline_oneclick.yaml)

### [This is part of a bigger project and can be found here](https://github.com/appbaseio-apps/song-search)

## Before starting

There are some pre-requisites for this pipeline to work properly.

### Setup mapping

In order for the vector data to be indexed properly, the vector fields need to be setup. This can be done by creating the index with some settings and mappings specified

Following request creates the mapping:

> NOTE that the `index`, `host` and `port` field need to be replaced with actual values

```sh
curl --location --request PUT 'https://{{host}}:{{port}}/{{index}}' \
--header 'Content-Type: application/json' \
--data-raw '{
    "settings": {
        "knn": true,
        "knn.algo_param.ef_search": 100
    },
    "mappings": {
        "properties": {
            "vector_data": {
                "type": "knn_vector",
                "dimension": 1536,
                "method": {
                    "name": "hnsw",
                    "space_type": "cosinesimil",
                    "engine": "nmslib"
                }
            }
        }
    }
}'
```

In the above request, one field is being created which will be used as vector fields during indexing process and will contain vector data.

This field is named as `vector_data`. Vector data of the `Summary` and `Text` fields will be stored in this field.

### OpenAI Embeddings

OpenAI API requires an API key in order to access the API. This API key can be generated by signing up at https://platform.openai.com/signup. Once signed up, click on `Personal` on the top right corner and click `View API keys`.

This API key will have to be passed to the pipeline so that it can use the API properly in order to get the data embeddings.

## Envs

Since the pipeline depends on OpenAI's API, the API Key needs to be passed as an environment variable.

- `OPENAI_API_KEY`: It is expected to be passed through the github action yaml file that will use the `pipelines-action` to resolve the filed dynamically from a GitHub Secret.

They can be passed in the following way

```yaml
- name: Deploy Pipeline
  uses: appbaseio/pipelines-action@0.1.1
  with:
    url: ${{secrets.APPBASEIOURL}}
    file: "./openai_indexing/pipeline.yaml"
  env:
    OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
```

Note that the `OPENAI_API_KEY` is extracted from GitHub Secret. ([Read about GitHub Secrets here](https://docs.github.com/en/actions/security-guides/encrypted-secrets)):

[Read more about passing envs to `pipelines-action` here](https://github.com/appbaseio/pipelines-action#environments)

## Auth

This stage is just to make sure that only authorized requests go through the first stage. Since pipelines are invoked when a defined route is matched, the user needs to take control of the authorization part themselves.

For this, we expose a pre defined stage `authorization` that does everything that ReactiveSearch API did (under the hood).

> It is encouraged that this stage is added in all pipeline definitions as the first step.

## Fetch Embeddings

This is the stage that does the fetching of the embeddings. This fetching is done by using a pre-built stage provided by ReactiveSearch. This stage is `openAIEmbeddingsIndex`. This stage takes care of reading from the request body, fetching the vector data and injecting the vector data back into the request body.

## Index Data

Now that we have the final document body ready, we need to index the data into ElasticSearch. This can be done by using the pre-built stage `elasticsearchQuery`.
